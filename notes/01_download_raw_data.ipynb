{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download\n",
    "\n",
    "> This module downloads the raw data from CDS and saves it in the local directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a similar approach to the one in the tutorial to download the data\n",
    "to local storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import hydra\n",
    "import cdsapi\n",
    "import tempfile\n",
    "import zipfile\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from pyprojroot import here\n",
    "from shapely.geometry import box\n",
    "from omegaconf import DictConfig, ListConfig, OmegaConf\n",
    "\n",
    "try: from era5_sandbox.core import _expand_path\n",
    "except: from core import _expand_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _validate_query(\n",
    "        query_body: DictConfig\n",
    "    )->bool:\n",
    "    '''\n",
    "    Check that the query is valid\n",
    "    '''\n",
    "\n",
    "    required_keys = ['product_type', 'variable', 'year', 'month', 'day', 'time', 'area', 'data_format', 'download_format']\n",
    "    if not all([key in query_body.keys() for key in required_keys]):\n",
    "        print(f\"Missing required key in query. Required keys are {required_keys}\")\n",
    "        print(\"Query validation failed\")\n",
    "        raise ValueError(\"Invalid query\")\n",
    "    \n",
    "    if isinstance(query_body['year'], ListConfig):\n",
    "        query_body['year'] = [str(x).zfill(2) for x in query_body['year']]\n",
    "    else:\n",
    "        query_body['year'] = str(query_body['year'])\n",
    "    if isinstance(query_body['month'], ListConfig):\n",
    "        query_body['month'] = [str(x).zfill(2) for x in query_body['month']]\n",
    "    else:\n",
    "        query_body['month'] = str(query_body['month']).zfill(2)\n",
    "    \n",
    "    if isinstance(query_body['day'], ListConfig):\n",
    "        query_body['day'] = [str(x).zfill(2) for x in query_body['day']]\n",
    "    else:\n",
    "        query_body['day'] = str(query_body['day']).zfill(2)\n",
    "\n",
    "    return OmegaConf.to_container(query_body, resolve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fetch_GADM(\n",
    "        url: str=\"https://geodata.ucdavis.edu/gadm/gadm4.1/gpkg/gadm41_MDG.gpkg\",\n",
    "        output_file: str=\"gadm41_MDG.gpkg\" # file path to save the GADM data\n",
    "    )-> str:\n",
    "    '''\n",
    "    Fetch the GADM data for Madagascar\n",
    "    https://geodata.ucdavis.edu/gadm/gadm4.1/gpkg/gadm41_MDG.gpkg\n",
    "    '''\n",
    "\n",
    "    output_file_path = _expand_path(output_file)\n",
    "    if os.path.exists(output_file_path):\n",
    "        print(\"GADM data already exists\")\n",
    "        return output_file_path\n",
    "    \n",
    "    print(\"Fetching GADM bounding box data for region\")\n",
    "    os.system(\"curl --output {} {}\".format(output_file, url))\n",
    "    print(\"GADM data fetched\")\n",
    "    \n",
    "    return output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_bounding_box(\n",
    "    zip_url_or_path: str,\n",
    "    buffer_km: float = 50,\n",
    "    round_to: int = 1\n",
    ") -> list:\n",
    "    '''\n",
    "    Create a bounding box from OCHA/HDX shapefile data with a buffer.\n",
    "\n",
    "    Parameters:\n",
    "        zip_url_or_path (str): URL or local path to the zipped shapefile.\n",
    "        buffer_km (float): Buffer distance in kilometers to expand the bounding box.\n",
    "        round_to (int): Number of decimal places to round the bounding box coordinates.\n",
    "\n",
    "    Returns:\n",
    "        list: Bounding box in the CDS API area format [North, West, South, East].\n",
    "    '''\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # Download if it's a URL\n",
    "        if zip_url_or_path.startswith(\"http\"):\n",
    "            response = requests.get(zip_url_or_path)\n",
    "            zip_path = os.path.join(tmpdir, \"ocha_data.zip\")\n",
    "            with open(zip_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            zip_path = zip_url_or_path\n",
    "\n",
    "        # Unzip\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(tmpdir)\n",
    "\n",
    "        # Find the .shp file\n",
    "        shp_files = list(Path(tmpdir).rglob(\"*.shp\"))\n",
    "        if not shp_files:\n",
    "            raise FileNotFoundError(\"No shapefile (.shp) found in the extracted archive.\")\n",
    "        shp_path = str(shp_files[0])  # Use first found .shp\n",
    "\n",
    "        # Read shapefile\n",
    "        shape = gpd.read_file(shp_path)\n",
    "\n",
    "        # Reproject to projected CRS (you may want to detect the correct UTM zone)\n",
    "        shape_proj = shape.to_crs(epsg=32738)\n",
    "\n",
    "        # Apply buffer\n",
    "        buffered = shape_proj.geometry.buffer(buffer_km * 1000)\n",
    "\n",
    "        # Convert back to geographic coordinates\n",
    "        buffered_geo = gpd.GeoSeries(buffered, crs=shape_proj.crs).to_crs(epsg=4326)\n",
    "\n",
    "        # Get bounding box\n",
    "        bounds = buffered_geo.total_bounds  # [min_x, min_y, max_x, max_y]\n",
    "        bbox = [\n",
    "            round(bounds[3], round_to),  # North\n",
    "            round(bounds[0], round_to),  # West\n",
    "            round(bounds[1], round_to),  # South\n",
    "            round(bounds[2], round_to)   # East\n",
    "        ]\n",
    "\n",
    "        return bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_raw_era5(\n",
    "        cfg: DictConfig  # hydra configuration file\n",
    "    )->None:\n",
    "    '''\n",
    "    Send the query to the API and download the data\n",
    "    '''\n",
    "\n",
    "    # parse the cfg\n",
    "    testing = cfg.development_mode # for testing\n",
    "    output_dir = here(\"data/input\") # output directory\n",
    "    \n",
    "    geography = cfg.query.geography\n",
    "\n",
    "    target = os.path.join(_expand_path(output_dir), \"{}_{}_{}.nc\".format(geography, cfg.query['year'], cfg.query['month']))\n",
    "    \n",
    "    client = cdsapi.Client()\n",
    "    \n",
    "    query = _validate_query(cfg.query)\n",
    "\n",
    "    dataset = cfg.dataset\n",
    "    # to make sure the query is valid at the end\n",
    "    del query['geography']\n",
    "    \n",
    "    # Send the query to the client\n",
    "    if not testing:\n",
    "        bounds = create_bounding_box(cfg.geographies[geography]['shapefile'])\n",
    "        query['area'] = bounds\n",
    "        client.retrieve(dataset, query).download(target)\n",
    "\n",
    "        print(\"Downloaded file to: {}\".format(target))\n",
    "    else:\n",
    "        print(f\"Testing mode. Not downloading data. Query is {query}\")\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests and Main\n",
    "\n",
    "Here we define some tests and the main function that will be used to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 16:45:08,085 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-05-14 16:45:08,085 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2025-05-14 16:45:11,277 INFO Request ID is 9ccc342d-9b35-4535-9558-032e1d7efe3d\n",
      "2025-05-14 16:45:11,406 INFO status has been updated to accepted\n",
      "2025-05-14 16:45:25,389 INFO status has been updated to running\n",
      "2025-05-14 16:51:31,605 INFO status has been updated to successful\n",
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file to: /net/rcstorenfs02/ifs/rc_labs/dominici_lab/lab/data_processing/csph-era5_sandbox/data/input/nepal_2017_11.nc\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# unfortunately, we have to use the initialize function to load the config file\n",
    "# this is because the @hydra decorator does not work with Notebooks very well\n",
    "# this is a known issue with Hydra: https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "# \n",
    "# just use the relative path from the notebook to the config dir\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "cfg.development_mode = False\n",
    "cfg.query['year'] = 2017\n",
    "cfg.query['month'] = 11\n",
    "#cfg.query['day'] = 1\n",
    "#cfg.query['time'] = \"00:00\"\n",
    "cfg.query['geography'] = \"nepal\"\n",
    "download_raw_era5(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@hydra.main(config_path=\"../../conf\", config_name=\"config\", version_base=None)\n",
    "def main(cfg: DictConfig) -> None:\n",
    "    download_raw_era5(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "try: from nbdev.imports import IN_NOTEBOOK\n",
    "except: IN_NOTEBOOK=False\n",
    "\n",
    "if __name__ == \"__main__\" and not IN_NOTEBOOK:\n",
    "    print('Running from __main__ ...')\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "era5_sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
