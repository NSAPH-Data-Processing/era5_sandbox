"""This is a core library for the ERA5 dataset pipeline. It defines"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../notes/00_core.ipynb.

# %% auto 0
__all__ = ['describe', 'kelvin_to_celsius', 'GoogleDriver', 'ClimateDataFileHandler', 'testAPI', 'main']

# %% ../../notes/00_core.ipynb 3
import os
import cdsapi
import hydra
import json
import tempfile
import argparse
import zipfile
import shutil
import geopandas as gpd
from pathlib import Path
from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive
from omegaconf import DictConfig, OmegaConf
from pyprojroot import here
from importlib import import_module


# %% ../../notes/00_core.ipynb 5
def describe(
    cfg: DictConfig=None,  # Configuration file
    )-> None:
    "Describe the configuration file used by Hydra for the pipeline"
    
    if cfg is None:
        print("No configuration file provided. Generating default configuration file.")
        cfg = OmegaConf.create()
        
    print("This package fetches ERA5 data. The following is the config file used by Hydra for the pipeline:\n")
    print(OmegaConf.to_yaml(cfg))

# %% ../../notes/00_core.ipynb 6
def _expand_path(
        path: str   # Path on user's machine
        )->   str:  # Expanded path
    "Expand the path on the user's machine for cross compatibility"

    # Expand ~ to the user's home directory
    path = os.path.expanduser(path)
    # Expand environment variables
    path = os.path.expandvars(path)
    # Convert to absolute path
    path = os.path.abspath(path)
    return path

# %% ../../notes/00_core.ipynb 7
def _get_callable(func_path):
    """Dynamically import a callable from a string path."""
    module_name, func_name = func_path.rsplit(".", 1)
    module = import_module(module_name)
    return getattr(module, func_name)

# %% ../../notes/00_core.ipynb 8
def _create_directory_structure(
        base_path: str,  # The base directory where the structure will be created
        structure: dict  # A dictionary representing the directory structure
    )->None:
    """
    Recursively creates a directory structure from a dictionary.

    Args:
        base_path (str): The base directory where the structure will be created.
        structure (dict): A dictionary representing the directory structure.
    """
    for folder, substructure in structure.items():
        # Create the current directory
        current_path = os.path.join(base_path, folder)
        os.makedirs(current_path, exist_ok=True)
        
        # Recursively create subdirectories if substructure is a dictionary
        if isinstance(substructure, dict):
            _create_directory_structure(current_path, substructure)

# %% ../../notes/00_core.ipynb 9
def kelvin_to_celsius(kelvin):
    """
    Convert temperature from Kelvin to Celsius.
    
    Args:
        kelvin (float): Temperature in Kelvin.
        
    Returns:
        float: Temperature in Celsius.
    """
    return kelvin - 273.15

# %% ../../notes/00_core.ipynb 11
class GoogleDriver:
    """
    A class to handle Google Drive authentication and file management.
    This class uses the PyDrive2 library to authenticate with Google Drive using a service account.
    
    It provides three methods: authenticating the account, getting the drive object, and downloading the healthshed files for madagascar.
    """
    def __init__(self, json_key_path=None):
        self.json_key_path = json_key_path or os.getenv("GOOGLE_DRIVE_AUTH_JSON")
        if not self.json_key_path or not os.path.isfile(self.json_key_path):
            raise FileNotFoundError(f"Service account key file not found: {self.json_key_path}")
        self.drive = self._authenticate()

    def _authenticate(self):

        settings = {
            "client_config_backend": "service",
            "service_config": {
                "client_json_file_path": self.json_key_path
            }
        }
        gauth = GoogleAuth(settings=settings)

        gauth.ServiceAuth()
        
        return GoogleDrive(gauth)

    def get_drive(self):
        return self.drive

# %% ../../notes/00_core.ipynb 20
from fastcore.basics import patch

# %% ../../notes/00_core.ipynb 21
@patch
def read_healthsheds(self:GoogleDriver, healthshed_zip_name):

    file_list = self.drive.ListFile({'q': f" title='{healthshed_zip_name}' and trashed = false "}).GetList()

    with tempfile.TemporaryDirectory() as temp_dir:
        # Create a temporary directory to store the downloaded file
        zip_path = os.path.join(temp_dir, healthshed_zip_name)

        # Download file from Google Drive
        file_obj = self.drive.CreateFile({'id': file_list[0]['id']})
        file_obj.GetContentFile(zip_path)

        # Read shapefile directly from ZIP
        gdf = gpd.read_file(f"zip://{zip_path}")

        # we need to ensure that the healthsheds only contain valid polygons
        gdf = gdf[gdf.geometry.notnull()]
        gdf.reset_index(drop=True, inplace=True)
        
        return gdf

# %% ../../notes/00_core.ipynb 25
class ClimateDataFileHandler:
    """
    A class to handle file operations for the Climate Data Store (CDS).
    This class provides unpack files downloaded from the CDS API. It must be able to
    handle the unpacking of files downloaded from the CDS API. This means that
    if the file is a basic netcdf, it should be passed to the netcdf handler. If
    the file is a zip, it should be handled by the zip handler in temp and the
    data returned as required.
    """

    def __init__(self, input_path: str):
        """
        Core initialization. It requires only the path. The flags are
        then used to do the handling logic.
        """
        self.original_path = Path(input_path)
        
        # major flag here for logic
        self.is_zip = False
        
        # the unzipping directory
        self.unzipped_dir = None
        
        # the instant data, such as temperature
        self.instant_file = None
        
        # the cumulative data, such as precipitation
        self.accum_file = None
        
        # any extraneous data
        self.other_files = []

        # ready to be used
        self._prepared = False

    def prepare(self):
        """
        Inspect the file and prepare the appropriate NetCDF paths.
        """
        if self._prepared:
            return

        if not self.original_path.exists():
            raise FileNotFoundError(f"{self.original_path} does not exist")

        # Detect ZIP by magic number
        # chatgpt implementation here; this is a common way to check for zip files
        with open(self.original_path, "rb") as f:
            sig = f.read(4)
            self.is_zip = sig == b'PK\x03\x04'

        if self.is_zip:
            self._unzip_and_scan()
        else:
            self.instant_file = str(self.original_path)

        self._prepared = True

    def _unzip_and_scan(self):
        """Extract and identify stepType-specific NetCDFs from ZIP."""
        self.unzipped_dir = tempfile.TemporaryDirectory()
        with zipfile.ZipFile(self.original_path, 'r') as zip_ref:
            zip_ref.extractall(self.unzipped_dir.name)

        for f in Path(self.unzipped_dir.name).glob("*.nc"):
            if "stepType-instant" in f.name:
                self.instant_file = str(f)
            elif "stepType-accum" in f.name:
                self.accum_file = str(f)
            else:
                self.other_files.append(str(f))

    def get_dataset(self, type: str = "instant") -> str:
        """Get the appropriate dataset path ('instant' or 'accum')."""
        self.prepare()

        if type == "instant" and self.instant_file:
            return self.instant_file
        elif type == "accum" and self.accum_file:
            return self.accum_file
        elif type == "any":
            return self.instant_file or self.accum_file or (self.other_files[0] if self.other_files else None)
        else:
            raise ValueError(f"No file found for requested type '{type}'")

    def cleanup(self):
        """Clean up any temporary directories created during unzip."""
        if self.unzipped_dir is not None:
            self.unzipped_dir.cleanup()

# %% ../../notes/00_core.ipynb 33
@patch
def __enter__(self:ClimateDataFileHandler):
    self.prepare()
    return self

@patch
def __exit__(self:ClimateDataFileHandler, exc_type, exc_val, exc_tb):
    self.cleanup()

# %% ../../notes/00_core.ipynb 36
def testAPI(
    cfg: DictConfig=None,
    dataset:str="reanalysis-era5-pressure-levels"
    )-> bool:    
    
    # parse config
    testing=cfg.development_mode
    output_path=here("data") / "testing"

    print(OmegaConf.to_yaml(cfg))

    try:
        client = cdsapi.Client()

        # build request
        request = {
            'product_type': ['reanalysis'],
            'variable': ['geopotential'],
            'year': ['2024'],
            'month': ['03'],
            'day': ['01'],
            'time': ['13:00'],
            'pressure_level': ['1000'],
            'data_format': 'grib',
        }

        target = output_path / 'test_download.grib'
        
        print("Testing API connection by downloading a dummy dataset to {}...".format(output_path))

        client.retrieve(dataset, request, target)

        if not testing:
            os.remove(target)
        
        print("API connection test successful.")
        return True

    except Exception as e:
        print("API connection test failed.")
        print("Did you set up your API key with CDS? If not, please visit https://cds.climate.copernicus.eu/how-to-api#install-the-cds-api-client")
        print("Error: {}".format(e))
        return False

# %% ../../notes/00_core.ipynb 40
@hydra.main(version_base=None, config_path="../../conf", config_name="config")
def main(cfg: DictConfig) -> None:

    # Create the directory structure
    _create_directory_structure(here() / "data", cfg.datapaths)

    # test the api
    testAPI(cfg=cfg)

# %% ../../notes/00_core.ipynb 41
#| eval: false
try: from nbdev.imports import IN_NOTEBOOK
except: IN_NOTEBOOK=False

if __name__ == "__main__" and not IN_NOTEBOOK:
    main()
